# Voice Extraction Pipeline

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

## Overview

This is a comprehensive Python-based pipeline designed to extract and process voice content from X/Twitter profiles. The pipeline validates accounts, collects profile data using Bright Data, extracts external links, filters for audio content from platforms like YouTube and Twitch, and uses OpenAI Whisper for advanced voice processing and transcription.

The pipeline is modular with 7 main stages, each building on the previous one to automate the extraction of high-quality voice samples from social media profiles. It includes comprehensive timing measurement, duplicate prevention, logging, and reporting features for efficient data management.

**ğŸ¤– AI Enhancement:** Integrated OpenAI Whisper for speech recognition, overlap detection, and transcription in stage 7.

Key goals:
- Validate and filter valid X/Twitter accounts.
- Collect profile data while avoiding redundant snapshots.
- Focus on voice-centric content from linked YouTube/Twitch channels.
- Extract and process voice samples for further analysis (e.g., AI voice modeling).

**Note:** This pipeline requires external dependencies like Bright Data API access, yt-dlp for downloads, ffmpeg for audio processing, and Playwright for web scraping. Ensure you comply with all platform terms of service and data usage policies.

## Features

- **Account Validation:** Checks if X/Twitter accounts exist using web scraping.
- **Snapshot Management:** Tracks and reuses Bright Data snapshots to prevent duplicates.
- **Data Collection:** Triggers and downloads profile data via Bright Data API.
- **Link Extraction & Filtering:** Identifies and filters external links to YouTube and Twitch.
- **Audio & Voice Detection:** Detects audio content and verifies voice presence (e.g., podcasts, streams).
- **Sample Extraction:** Downloads short audio samples with filename including username and source.
- **Advanced Voice Processing:** Uses VAD (Voice Activity Detection) and speech recognition to extract voice-only segments.
- **Logging & Reporting:** Maintains logs, summaries, and reports for snapshots and extractions.
- **Concurrency & Delays:** Built-in delays and concurrency limits to avoid rate limiting.

## Requirements

- **Python:** 3.8 or higher.
- **Libraries:** Install via `pip install -r requirements.txt` (create this file with the following):

git clone https://github.com/your-repo/voice-extraction-pipeline.git
cd voice-extraction-pipeline


2. Install Python dependencies:
pip install -r requirements.txt


3. Install external tools:
- Install ffmpeg: Download from official site or use package manager (e.g., `brew install ffmpeg` on macOS, `apt install ffmpeg` on Ubuntu).
- Install yt-dlp: `pip install yt-dlp`.
- Install Playwright browsers: `playwright install`.

4. Set up configuration:
- Create a `.env` file or set environment variables for Bright Data:
  ```
  BRIGHT_DATA_TOKEN=your_api_token
  BRIGHT_DATA_DATASET_ID=your_dataset_id
  ```
 5. config.json and config.py ( put your token in both files )


## Usage

The pipeline is divided into sequential steps. Run them in order, or integrate into a main script. Outputs from one step feed into the next (e.g., via CSV files).

### Individual Stages
Run specific stages independently:

```bash
# Stage 1: Account Validation
python main_pipeline.py --stage1-only sample_usernames.csv

# Stage 2: Bright Data Trigger
python main_pipeline.py --stage2-only output/1_existing_accounts.csv

# Stage 3: Data Download
python main_pipeline.py --stage3-only s_snapshot_id

# Stage 3.5: YouTube/Twitch Discovery (Optional)
python main_pipeline.py --stage3_5-only output/3_snapshot_xyz_external_links.csv

# Stage 4: Audio Platform Filtering
python main_pipeline.py --stage4-only output/3_snapshot_xyz_external_links.csv

# Stage 5: Audio Content Detection
python main_pipeline.py --stage5-only output/4_snapshot_xyz_audio_links.csv

# Stage 6: Voice Sample Extraction
python main_pipeline.py --stage6-only output/5_snapshot_xyz_audio_detected.csv

# Stage 7: Advanced Whisper Analysis
python main_pipeline.py --stage7-only output/voice_samples/
```

### Full Pipeline Example
Create a main.py to chain steps, e.g.:
Pseudocode

validated = validate_accounts('usernames.txt')
snapshot_id = trigger_snapshot(validated)
data = download_snapshot(snapshot_id)
links = extract_links(data)
audio_links = filter_audio(links)
voice_links = verify_voice(audio_links)
samples = extract_samples(voice_links)
processed = process_voice(samples)


## Configuration

- **Output Directories:** Defaults to `output/`, `voice_samples/`, `voice_analysis/`. Customize via CLI args.
- **Delays & Concurrency:** Adjustable in classes (e.g., `AccountValidator` for min/max delays).
- **API Tokens:** Store securely in environment variables.
- **Logging:** Processed logs saved as JSON (e.g., `processed_accounts.json`).

## Project Structure

```
x-audio-content-pipeline/
â”œâ”€â”€ ğŸ“ Core Pipeline Files
â”‚   â”œâ”€â”€ main_pipeline.py                    # ğŸ¯ Main orchestrator with all 7 stages
â”‚   â”œâ”€â”€ config.py                          # âš™ï¸ Configuration settings
â”‚   â”œâ”€â”€ config_example.py                  # ğŸ“‹ Configuration template
â”‚   â”œâ”€â”€ config.json                        # ğŸ”§ Additional JSON configuration
â”‚   â””â”€â”€ requirements.txt                   # ğŸ“¦ Python dependencies
â”‚
â”œâ”€â”€ ğŸ“ Pipeline Stages
â”‚   â”œâ”€â”€ step1_validate_accounts.py         # âœ… Stage 1: Account validation
â”‚   â”œâ”€â”€ step2_bright_data_trigger.py       # ğŸš€ Stage 2: Snapshot management
â”‚   â”œâ”€â”€ step3_bright_data_download.py      # â¬‡ï¸ Stage 3: Data download
â”‚   â”œâ”€â”€ step3_5_youtube_twitch_runner.py   # ğŸ” Stage 3.5: Channel discovery
â”‚   â”œâ”€â”€ step4_audio_filter.py              # ğŸ¯ Stage 4: Audio platform filter
â”‚   â”œâ”€â”€ step5_voice_detector.py            # ğŸµ Stage 5: Voice detection
â”‚   â”œâ”€â”€ step6_voice_sample_extractor.py    # ğŸ¤ Stage 6: Sample extraction
â”‚   â””â”€â”€ step7_advanced_voice_processor.py  # ğŸ¤– Stage 7: Whisper processing
â”‚
â”œâ”€â”€ ğŸ“ Utilities
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py                    # Package initialization
â”‚   â”‚   â”œâ”€â”€ checker_web.py                 # ğŸŒ Web validation utilities
â”‚   â”‚   â”œâ”€â”€ io_utils.py                    # ğŸ“‚ I/O helper functions
â”‚   â”‚   â””â”€â”€ username_utils.py              # ğŸ‘¤ Username processing
â”‚   â”œâ”€â”€ snapshot_manager.py                # ğŸ“Š Snapshot lifecycle management
â”‚   â”œâ”€â”€ audio_from_youtube.py              # ğŸµ YouTube audio utilities
â”‚   â””â”€â”€ split_chunks.py                    # âœ‚ï¸ Audio chunking utilities
â”‚
â”œâ”€â”€ ğŸ“ External Scraper
â”‚   â””â”€â”€ youtube-twitch-x-scraper/          # ğŸ” Enhanced channel discovery
â”‚       â”œâ”€â”€ youtube_twitch_scraper.py      # Main scraper implementation
â”‚       â”œâ”€â”€ enhanced_matching.py           # Advanced matching algorithms
â”‚       â”œâ”€â”€ config.py                      # Scraper configuration
â”‚       â”œâ”€â”€ requirements.txt               # Scraper dependencies
â”‚       â”œâ”€â”€ proxy/                         # Proxy configuration
â”‚       â””â”€â”€ README.md                      # Scraper documentation
â”‚
â”œâ”€â”€ ğŸ“ Input/Output
â”‚   â”œâ”€â”€ input/                             # ğŸ“¥ Input files directory
â”‚   â”‚   â”œâ”€â”€ merged_user_all_usernames.csv  # Combined username datasets
â”‚   â”‚   â”œâ”€â”€ merged_user_mbti.csv           # MBTI personality data
â”‚   â”‚   â””â”€â”€ users_twitter.csv              # Twitter user data
â”‚   â”œâ”€â”€ output/                            # ğŸ“¤ Pipeline output directory
â”‚   â”‚   â”œâ”€â”€ snapshots/                     # ğŸ“Š Snapshot metadata
â”‚   â”‚   â”œâ”€â”€ voice_samples/                 # ğŸ¤ Extracted MP3 files
â”‚   â”‚   â”œâ”€â”€ processed_accounts.json        # ğŸ“‹ Account validation log
â”‚   â”‚   â”œâ”€â”€ 1_existing_accounts.csv        # âœ… Stage 1 output
â”‚   â”‚   â”œâ”€â”€ 2_snapshot_*_results.csv       # ğŸ“Š Stage 2-3 output
â”‚   â”‚   â”œâ”€â”€ 3_snapshot_*_external_links.csv # ğŸ”— Stage 3 output
â”‚   â”‚   â”œâ”€â”€ 4_*_audio_links.csv            # ğŸ¯ Stage 4 output
â”‚   â”‚   â”œâ”€â”€ 5_*_audio_detected.csv         # ğŸµ Stage 5 output
â”‚   â”‚   â”œâ”€â”€ 6_voice_samples_results.csv    # ğŸ¤ Stage 6 output
â”‚   â”‚   â””â”€â”€ 7_whisper_results.csv          # ğŸ“ Stage 7 output
â”‚   â””â”€â”€ output_audio2/                     # ğŸµ Alternative audio output
â”‚
â”œâ”€â”€ ğŸ“ Configuration & Samples
â”‚   â””â”€â”€ sample_usernames.csv               # ğŸ“‹ Example input file
â”‚
â””â”€â”€ ğŸ“ Development
    â”œâ”€â”€ .gitignore                         # ğŸš« Git ignore rules
    â”œâ”€â”€ .venv/                             # ğŸ Python virtual environment
    â”œâ”€â”€ __pycache__/                       # ğŸ—‚ï¸ Python cache files
    â””â”€â”€ README.md                          # ğŸ“– This documentation
```

### Key Components

#### ğŸ¯ Main Pipeline (`main_pipeline.py`)
- **Full Pipeline:** Complete 7-stage execution with timing
- **Individual Stages:** Run any stage independently
- **Timing Measurement:** Comprehensive execution time tracking
- **Error Handling:** Robust error management and recovery
- **CLI Interface:** Rich command-line interface with help

#### ğŸ¤– Whisper Integration
- **Stage 7:** Advanced Whisper analysis with transcription
- **Features:** Voice activity detection, overlap detection, transcription generation
- **Output:** Clean WAV files + detailed transcription metadata

#### ğŸ“Š Data Flow
```
Input CSV â†’ Stage 1 â†’ Stage 2 â†’ Stage 3 â†’ (Stage 3.5) â†’ Stage 4 â†’ Stage 5 â†’ Stage 6 â†’ Stage 7
    â†“           â†“         â†“         â†“           â†“            â†“         â†“         â†“           â†“
Usernames â†’ Accounts â†’ Snapshots â†’ Links â†’ Enhanced â†’ Audio â†’ Voice â†’ MP3 â†’ WAV+Whisper â†’ Transcripts
```

#### ğŸ”§ Configuration Files
- **`config.py`:** Main configuration (API tokens, settings)
- **`config_example.py`:** Template for new setups
- **`config.json`:** Additional JSON-based configuration

#### ğŸ“¦ Dependencies
- **Core:** pandas, requests, asyncio, aiohttp
- **Audio:** yt-dlp, ffmpeg-python, pydub
- **AI:** openai-whisper, torch, transformers
- **Web:** playwright, beautifulsoup4, selenium

## Troubleshooting

- **Timeouts/Errors:** Increase delays or reduce concurrency.
- **Dependencies Missing:** Ensure ffmpeg and yt-dlp are in PATH.
- **API Issues:** Verify Bright Data token and dataset ID.
- **No Voice Detected:** Adjust confidence thresholds in processors.

## Contributing

Pull requests welcome! For major changes, open an issue first.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

*Generated on Monday, August 18, 2025.*
