#!/usr/bin/env python3
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π Video Voice Filter —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –≥–æ–ª–æ—Å–∞
"""
import argparse
import json
import pandas as pd
import logging
import sys
import tempfile
import os
from pathlib import Path
from typing import List, Dict, Optional
import time
from datetime import datetime

# –ê—É–¥–∏–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    import yt_dlp
    import numpy as np
    from pydub import AudioSegment
    import librosa
    AUDIO_LIBS_AVAILABLE = True
except ImportError as e:
    print(f"‚ùå Missing audio libraries: {e}")
    AUDIO_LIBS_AVAILABLE = False

class EnhancedVoiceDetector:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ—á–∏ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
    
    def __init__(self, config_path: str = "config.json"):
        self._setup_logging()
        self.config = self._load_config(config_path)
        self.voice_threshold = self.config.get('voice_threshold', 0.6)
        self.logger.info("‚úÖ EnhancedVoiceDetector initialized")
    
    def _load_config(self, config_path: str) -> Dict:
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {
                'voice_threshold': 0.6,
                'min_speech_duration': 2.0,
                'energy_threshold_ratio': 0.3
            }
    
    def _setup_logging(self):
        self.logger = logging.getLogger(__name__)
        if not self.logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    def detect_audio_content(self, links: List[Dict]) -> List[Dict]:
        """–î–µ—Ç–µ–∫—Ü–∏—è –≥–æ–ª–æ—Å–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏"""
        if not AUDIO_LIBS_AVAILABLE:
            self.logger.error("‚ùå Required audio libraries not available")
            return []
            
        results = []
        for link in links:
            url = link.get("url")
            username = link.get("username", "unknown")
            platform = link.get("platform_type", "unknown")
            
            self.logger.info(f"üé§ Analyzing {username} ({platform})")
            
            try:
                voice_result = self._analyze_video_audio(url, username)
                result = {
                    "username": username,
                    "url": url,
                    "platform_type": platform,
                    **voice_result
                }
                results.append(result)
                
            except Exception as e:
                self.logger.error(f"‚ùå Error analyzing {url}: {e}")
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –æ—à–∏–±–∫–æ–π
                results.append({
                    "username": username,
                    "url": url,
                    "platform_type": platform,
                    "voice_detected": False,
                    "voice_probability": 0.0,
                    "audio_confidence": "error",
                    "detection_method": "error",
                    "error": str(e)
                })
        
        return results
    
    def _analyze_video_audio(self, url: str, username: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –æ–ø—Ü–∏–∏ yt-dlp
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
            temp_path = tmpfile.name
        
        try:
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': temp_path.replace('.wav', '.%(ext)s'),
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'wav',
                    'preferredquality': '192',
                }],
                'quiet': True,
                'no_warnings': True,
                'socket_timeout': 30,
                'retries': 2,
                # ‚úÖ –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 60 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                'download_sections': '*0-60'  
            }
            
            self.logger.info(f"üì• Downloading audio sample from {url[:50]}...")
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])
            
            # –ù–∞–π—Ç–∏ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
            audio_file = None
            for ext in ['.wav', '.m4a', '.webm', '.mp3', '.ogg']:
                candidate = temp_path.replace('.wav', ext)
                if os.path.exists(candidate):
                    audio_file = candidate
                    break
            
            if not audio_file or not os.path.exists(audio_file):
                raise Exception("Audio file not downloaded")
            
            # ‚úÖ –£–õ–£–ß–®–ï–ù–ù–´–ô –∞–Ω–∞–ª–∏–∑ –≥–æ–ª–æ—Å–∞
            return self._multi_method_voice_detection(audio_file, username)
            
        finally:
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            for ext in ['.wav', '.m4a', '.webm', '.mp3', '.ogg']:
                candidate = temp_path.replace('.wav', ext)
                try:
                    if os.path.exists(candidate):
                        os.remove(candidate)
                except:
                    pass
    
    def _multi_method_voice_detection(self, audio_file: str, username: str) -> Dict:
        """–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–æ–ª–æ—Å–∞"""
        
        # –ú–µ—Ç–æ–¥ 1: –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (—É–ª—É—á—à–µ–Ω–Ω—ã–π)
        energy_result = self._energy_based_detection(audio_file)
        
        # –ú–µ—Ç–æ–¥ 2: –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        spectral_result = self._spectral_voice_detection(audio_file)
        
        # –ú–µ—Ç–æ–¥ 3: –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        frequency_result = self._frequency_analysis(audio_file)
        
        # ‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –≤–µ—Å–∞–º–∏
        methods = [
            (energy_result, 0.3, "energy"),
            (spectral_result, 0.4, "spectral"), 
            (frequency_result, 0.3, "frequency")
        ]
        
        final_probability = 0.0
        confidence_scores = []
        used_methods = []
        
        for result, weight, method_name in methods:
            if result['success']:
                final_probability += result['probability'] * weight
                confidence_scores.append(result['confidence'])
                used_methods.append(method_name)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if len(confidence_scores) >= 2:
            avg_confidence = np.mean(confidence_scores)
            if avg_confidence > 0.7:
                audio_confidence = "high"
            elif avg_confidence > 0.4:
                audio_confidence = "medium" 
            else:
                audio_confidence = "low"
        else:
            audio_confidence = "low"
        
        voice_detected = final_probability >= self.voice_threshold
        
        self.logger.info(f"üìä {username}: prob={final_probability:.3f}, conf={audio_confidence}")
        
        return {
            "voice_detected": voice_detected,
            "voice_probability": final_probability,
            "audio_confidence": audio_confidence,
            "detection_method": "+".join(used_methods),
            "has_voice_content": voice_detected,
            "method_details": {
                "energy": energy_result,
                "spectral": spectral_result,
                "frequency": frequency_result
            }
        }
    
    def _energy_based_detection(self, audio_file: str) -> Dict:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
            y, sr = librosa.load(audio_file, sr=16000, duration=60)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ñ—Ä–µ–π–º—ã
            frame_length = int(0.025 * sr)  # 25ms —Ñ—Ä–µ–π–º—ã
            hop_length = int(0.01 * sr)     # 10ms —à–∞–≥
            
            frames = librosa.util.frame(y, frame_length=frame_length, 
                                      hop_length=hop_length, axis=0)
            
            # ‚úÖ –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω–µ—Ä–≥–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–µ–π–º–∞
            energy = np.sum(frames ** 2, axis=0)
            
            # ‚úÖ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥
            max_energy = np.max(energy)
            mean_energy = np.mean(energy)
            threshold = mean_energy + 0.3 * (max_energy - mean_energy)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ—á–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            speech_frames = energy > threshold
            speech_ratio = np.sum(speech_frames) / len(speech_frames)
            
            # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç—å —Ä–µ—á–∏
            speech_segments = self._find_continuous_segments(speech_frames)
            long_segments = [seg for seg in speech_segments if seg[1] - seg[0] > sr * 0.5]  # >0.5 —Å–µ–∫
            
            probability = min(1.0, speech_ratio * 2)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            confidence = len(long_segments) / max(1, len(speech_segments))
            
            return {
                'success': True,
                'probability': probability,
                'confidence': confidence,
                'speech_ratio': speech_ratio,
                'segments_count': len(speech_segments)
            }
            
        except Exception as e:
            self.logger.error(f"Energy detection failed: {e}")
            return {'success': False, 'probability': 0.0, 'confidence': 0.0}
    
    def _spectral_voice_detection(self, audio_file: str) -> Dict:
        """–°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–æ–ª–æ—Å–∞"""
        try:
            y, sr = librosa.load(audio_file, sr=16000, duration=60)
            
            # ‚úÖ –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]
            
            # ‚úÖ –ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Ä–µ—á–∏
            # –ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è —Ä–µ—á—å: spectral centroid 200-4000 Hz
            voice_centroids = spectral_centroids[(spectral_centroids > 200) & 
                                                (spectral_centroids < 4000)]
            voice_ratio = len(voice_centroids) / len(spectral_centroids)
            
            # ZCR –¥–ª—è —Ä–µ—á–∏ –æ–±—ã—á–Ω–æ 50-200 –ì—Ü
            voice_zcr = zero_crossing_rate[(zero_crossing_rate > 0.01) & 
                                          (zero_crossing_rate < 0.3)]
            zcr_ratio = len(voice_zcr) / len(zero_crossing_rate)
            
            # MFCC –¥–∏—Å–ø–µ—Ä—Å–∏—è (—Ä–µ—á—å –∏–º–µ–µ—Ç –±–æ–ª—å—à–µ –≤–∞—Ä–∏–∞—Ü–∏–∏)
            mfcc_variance = np.var(mfccs, axis=1).mean()
            
            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            probability = (voice_ratio * 0.4 + zcr_ratio * 0.3 + 
                          min(1.0, mfcc_variance / 10) * 0.3)
            
            confidence = (voice_ratio + zcr_ratio) / 2
            
            return {
                'success': True,
                'probability': probability,
                'confidence': confidence,
                'voice_ratio': voice_ratio,
                'zcr_ratio': zcr_ratio
            }
            
        except Exception as e:
            self.logger.error(f"Spectral detection failed: {e}")
            return {'success': False, 'probability': 0.0, 'confidence': 0.0}
    
    def _frequency_analysis(self, audio_file: str) -> Dict:
        """–ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≥–æ–ª–æ—Å–∞"""
        try:
            y, sr = librosa.load(audio_file, sr=16000, duration=60)
            
            # ‚úÖ –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ —Å–ø–µ–∫—Ç—Ä–∞
            D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
            
            # –ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è —Ä–µ—á—å: 80-1000 Hz (–æ—Å–Ω–æ–≤–Ω—ã–µ —á–∞—Å—Ç–æ—Ç—ã), 1000-4000 Hz (—Ñ–æ—Ä–º–∞–Ω—Ç—ã)
            freqs = librosa.fft_frequencies(sr=sr)
            
            # –≠–Ω–µ—Ä–≥–∏—è –≤ —Ä–µ—á–µ–≤–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            speech_freq_mask = (freqs >= 80) & (freqs <= 4000)
            speech_energy = np.mean(D[speech_freq_mask, :])
            
            # –≠–Ω–µ—Ä–≥–∏—è –≤ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ (–≤—ã—à–µ 4000 Hz)
            music_freq_mask = freqs > 4000
            music_energy = np.mean(D[music_freq_mask, :])
            
            # –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–µ—á–µ–≤–æ–π —ç–Ω–µ—Ä–≥–∏–∏ –∫ –æ–±—â–µ–π
            total_energy = np.mean(D)
            if total_energy > 0:
                speech_ratio = speech_energy / total_energy
                probability = min(1.0, max(0.0, (speech_ratio - 0.3) * 2))  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            else:
                probability = 0.0
            
            confidence = min(1.0, abs(speech_energy - music_energy) / 40)  # –†–∞–∑–ª–∏—á–∏–º–æ—Å—Ç—å
            
            return {
                'success': True,
                'probability': probability,
                'confidence': confidence,
                'speech_energy': float(speech_energy),
                'music_energy': float(music_energy)
            }
            
        except Exception as e:
            self.logger.error(f"Frequency analysis failed: {e}")
            return {'success': False, 'probability': 0.0, 'confidence': 0.0}
    
    def _find_continuous_segments(self, binary_array: np.ndarray) -> List[tuple]:
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã True –≤ –±—É–ª–µ–≤–æ–º –º–∞—Å—Å–∏–≤–µ"""
        segments = []
        start = None
        
        for i, val in enumerate(binary_array):
            if val and start is None:
                start = i
            elif not val and start is not None:
                segments.append((start, i))
                start = None
        
        if start is not None:
            segments.append((start, len(binary_array)))
        
        return segments


class ChannelVideoFetcher:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –≤–∏–¥–µ–æ –∏–∑ –∫–∞–Ω–∞–ª–æ–≤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    def get_latest_video(self, channel_url: str, platform: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤–∏–¥–µ–æ –∏–∑ –∫–∞–Ω–∞–ª–∞"""
        
        try:
            if platform == 'youtube':
                return self._get_youtube_latest(channel_url)
            elif platform == 'twitch':
                return self._get_twitch_latest(channel_url)
            elif platform == 'tiktok':
                return self._get_tiktok_latest(channel_url)
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"Error fetching from {channel_url}: {e}")
            return None
    
    def _get_youtube_latest(self, channel_url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤–∏–¥–µ–æ —Å YouTube –∫–∞–Ω–∞–ª–∞"""
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ URL –≤–∏–¥–µ–æ –∫–∞–Ω–∞–ª–∞
        if not channel_url.endswith('/videos'):
            if '/@' in channel_url:
                channel_url = channel_url.split('?')[0].rstrip('/') + '/videos'
            elif '/channel/' in channel_url or '/c/' in channel_url:
                channel_url = channel_url.rstrip('/') + '/videos'
        
        ydl_opts = {
            'quiet': True,
            'extract_flat': True,
            'playlistend': 1  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤–∏–¥–µ–æ
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                playlist_info = ydl.extract_info(channel_url, download=False)
                
                if playlist_info and 'entries' in playlist_info:
                    first_entry = next(iter(playlist_info['entries']), None)
                    if first_entry and first_entry.get('id'):
                        return f"https://www.youtube.com/watch?v={first_entry['id']}"
                        
        except Exception as e:
            self.logger.error(f"YouTube fetch error: {e}")
        
        return None
    
    def _get_twitch_latest(self, channel_url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π VOD —Å Twitch –∫–∞–Ω–∞–ª–∞"""
        
        if '/videos' not in channel_url:
            channel_url = channel_url.rstrip('/') + '/videos'
        
        ydl_opts = {
            'quiet': True,
            'extract_flat': True,
            'playlistend': 1
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                playlist_info = ydl.extract_info(channel_url, download=False)
                
                if playlist_info and 'entries' in playlist_info:
                    first_entry = next(iter(playlist_info['entries']), None)
                    if first_entry and first_entry.get('url'):
                        return first_entry['url']
                        
        except Exception as e:
            self.logger.error(f"Twitch fetch error: {e}")
        
        return None
    
    def _get_tiktok_latest(self, channel_url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤–∏–¥–µ–æ —Å TikTok –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        
        ydl_opts = {
            'quiet': True,
            'extract_flat': True,
            'playlistend': 1
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                playlist_info = ydl.extract_info(channel_url, download=False)
                
                if playlist_info and 'entries' in playlist_info:
                    first_entry = next(iter(playlist_info['entries']), None)
                    if first_entry and first_entry.get('url'):
                        return first_entry['url']
                        
        except Exception as e:
            self.logger.error(f"TikTok fetch error: {e}")
        
        return None


class VideoVoiceFilter:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
    
    def __init__(self, config_path: str = "config.json"):
        self._setup_logging()
        self.voice_detector = EnhancedVoiceDetector(config_path)
        self.video_fetcher = ChannelVideoFetcher()
        self.min_voice_probability = 0.6
    
    def _setup_logging(self):
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def load_channels_from_csv(self, input_file: str) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ CSV"""
        try:
            df = pd.read_csv(input_file)
            channels = []
            
            for _, row in df.iterrows():
                if pd.isna(row.get("url")) or pd.isna(row.get("platform_type")):
                    continue
                
                platform = str(row["platform_type"]).lower()
                if platform not in ["youtube", "twitch", "tiktok"]:
                    continue
                
                url = str(row["url"])
                url_type = str(row.get("url_type", "unknown")).lower()
                
                channels.append({
                    "original_url": url,
                    "platform": platform,
                    "username": str(row.get("username", "unknown")),
                    "title": str(row.get("title", "unknown")),
                    "url_type": url_type,
                    "is_direct_video": url_type == "video"
                })
            
            return channels
            
        except Exception as e:
            self.logger.error(f"Error loading CSV: {e}")
            return []
    
    def process_channels(self, channels: List[Dict]) -> List[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–Ω–∞–ª–æ–≤"""
        
        print(f"\nüé¨ Processing {len(channels)} items...")
        voice_items = []
        
        for i, ch in enumerate(channels, 1):
            print(f"\nüì∫ [{i}/{len(channels)}] {ch['username']} ({ch['platform'].upper()})")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            if ch['is_direct_video']:
                video_url = ch['original_url']
                print(f"üé• Direct video: {ch['title'][:50]}...")
            else:
                print("üîç Fetching latest video from channel...")
                video_url = self.video_fetcher.get_latest_video(
                    ch['original_url'], 
                    ch['platform']
                )
                
                if not video_url:
                    print("‚ùå No video found or channel inaccessible")
                    continue
                    
                print(f"üìπ Found latest video: {video_url[:60]}...")
            
            # –ê–Ω–∞–ª–∏–∑ –≥–æ–ª–æ—Å–∞
            detection_data = [{
                "url": video_url,
                "platform_type": ch["platform"],
                "username": ch["username"]
            }]
            
            results = self.voice_detector.detect_audio_content(detection_data)
            
            if results and self._meets_voice_criteria(results[0]):
                result = results[0]
                voice_item = {
                    **ch,
                    "video_url": video_url,
                    "voice_probability": result.get("voice_probability", 0.0),
                    "audio_confidence": result.get("audio_confidence", "low"),
                    "detection_method": result.get("detection_method", "unknown"),
                    "timestamp": datetime.now().isoformat()
                }
                
                voice_items.append(voice_item)
                print(f"‚úÖ VOICE DETECTED! Probability: {result.get('voice_probability', 0):.3f}")
            else:
                print("‚ùå No voice detected or criteria not met")
            
            time.sleep(1)  # Rate limiting
        
        print(f"\nüìä RESULTS: {len(voice_items)}/{len(channels)} channels have voice content")
        return voice_items
    
    def _meets_voice_criteria(self, result: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –≥–æ–ª–æ—Å–∞"""
        if result.get("audio_confidence") == "error":
            return False
            
        voice_prob = result.get("voice_probability", 0.0)
        confidence = result.get("audio_confidence", "low")
        
        return (voice_prob >= self.min_voice_probability and 
                confidence in ["high", "medium"])
    
    def save_results(self, voice_items: List[Dict], output_file: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            if voice_items:
                df = pd.DataFrame(voice_items)
                df.to_csv(output_file, index=False)
                print(f"‚úÖ Results saved to {output_file}")
            else:
                print("‚ùå No voice items found")
        except Exception as e:
            self.logger.error(f"Error saving: {e}")


def main():
    if not AUDIO_LIBS_AVAILABLE:
        print("‚ùå Install required packages: pip install yt-dlp librosa pydub numpy")
        return
    
    parser = argparse.ArgumentParser(description="Filter channels by voice content")
    parser.add_argument("input_file", help="CSV file")
    parser.add_argument("-o", "--output", default="voice_results.csv", help="Output CSV")
    
    args = parser.parse_args()
    
    filter_tool = VideoVoiceFilter()
    channels = filter_tool.load_channels_from_csv(args.input_file)
    
    if not channels:
        print("‚ùå No valid channels loaded")
        return
    
    voice_items = filter_tool.process_channels(channels)
    filter_tool.save_results(voice_items, args.output)

if __name__ == "__main__":
    main()
